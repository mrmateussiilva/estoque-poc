# üöÄ Plano de Otimiza√ß√µes Go - Aproveitando ao M√°ximo as Habilidades do Go

Este documento apresenta um plano estruturado para aproveitar ao m√°ximo as capacidades do Go no sistema S.G.E., focando em performance, concorr√™ncia, e padr√µes idiom√°ticos da linguagem.

---

## üìä An√°lise do Estado Atual

### ‚úÖ O que j√° est√° sendo usado:
- ‚úÖ Goroutines b√°sicas (nfe_consumer)
- ‚úÖ Channels b√°sicos (email processing)
- ‚úÖ Context.Context (nfe_consumer)
- ‚úÖ Structured logging (slog)
- ‚úÖ Error handling customizado

### ‚ùå O que pode ser melhorado:
- ‚ùå Cache in-memory simples (pode usar sync.Map ou cache mais sofisticado)
- ‚ùå Processamento de NF-e sequencial (pode ser paralelo)
- ‚ùå Queries sem connection pooling otimizado
- ‚ùå Falta de worker pools para tarefas pesadas
- ‚ùå Sem graceful shutdown
- ‚ùå Sem m√©tricas/observabilidade nativa
- ‚ùå Sem rate limiting inteligente por usu√°rio
- ‚ùå Exporta√ß√µes grandes podem travar o servidor

---

## üéØ Objetivos do Plano

1. **Performance**: Reduzir lat√™ncia e aumentar throughput
2. **Concorr√™ncia**: Aproveitar m√∫ltiplos cores para processamento paralelo
3. **Escalabilidade**: Preparar para crescimento de carga
4. **Confiabilidade**: Graceful shutdown, retry logic, circuit breakers
5. **Observabilidade**: M√©tricas, tracing, profiling

---

## üìã Fase 1: Concorr√™ncia e Worker Pools (ALTA PRIORIDADE)

### 1.1 Worker Pool para Processamento de NF-e
**Problema**: Upload de NF-e processa sequencialmente, bloqueando outras requisi√ß√µes

**Solu√ß√£o**: Worker pool com goroutines para processar m√∫ltiplas NF-es em paralelo

```go
// internal/services/nfe_worker_pool.go
type NFeWorkerPool struct {
    workers    int
    jobQueue   chan NFeJob
    resultChan chan NFeResult
    wg         sync.WaitGroup
    db         *gorm.DB
}

type NFeJob struct {
    XMLData []byte
    UserID  int32
}

type NFeResult struct {
    Success bool
    Items   int
    Error   error
}

func NewNFeWorkerPool(workers int, db *gorm.DB) *NFeWorkerPool {
    return &NFeWorkerPool{
        workers:    workers,
        jobQueue:   make(chan NFeJob, 100), // Buffer de 100 jobs
        resultChan: make(chan NFeResult, 100),
        db:         db,
    }
}

func (p *NFeWorkerPool) Start(ctx context.Context) {
    for i := 0; i < p.workers; i++ {
        p.wg.Add(1)
        go p.worker(ctx, i)
    }
}

func (p *NFeWorkerPool) worker(ctx context.Context, id int) {
    defer p.wg.Done()
    nfeService := services.NewNfeService(p.db)
    
    for {
        select {
        case <-ctx.Done():
            return
        case job := <-p.jobQueue:
            // Processar NF-e
            result := p.processNFe(nfeService, job)
            p.resultChan <- result
        }
    }
}

func (p *NFeWorkerPool) Submit(job NFeJob) {
    p.jobQueue <- job
}

func (p *NFeWorkerPool) Wait() {
    close(p.jobQueue)
    p.wg.Wait()
    close(p.resultChan)
}
```

**Benef√≠cios**:
- Processa m√∫ltiplas NF-es simultaneamente
- N√£o bloqueia requisi√ß√µes HTTP
- Controle de concorr√™ncia (evita sobrecarga do DB)

**Impacto**: ‚ö°‚ö°‚ö° Alto - Reduz tempo de resposta de uploads

---

### 1.2 Worker Pool para Exporta√ß√µes CSV
**Problema**: Exporta√ß√µes grandes podem travar o servidor

**Solu√ß√£o**: Processar exporta√ß√µes em background com worker pool

```go
// internal/services/export_worker_pool.go
type ExportWorkerPool struct {
    workers  int
    jobQueue chan ExportJob
    db       *gorm.DB
}

type ExportJob struct {
    Type     string // "stock" | "movements"
    Filters  map[string]string
    UserID   int32
    FilePath string
}

func (p *ExportWorkerPool) ProcessExport(ctx context.Context, job ExportJob) error {
    // Processar em goroutine separada
    // Salvar arquivo e notificar usu√°rio via WebSocket ou polling
}
```

**Benef√≠cios**:
- Exporta√ß√µes n√£o bloqueiam servidor
- Usu√°rio pode continuar navegando
- Suporta exporta√ß√µes muito grandes

**Impacto**: ‚ö°‚ö° M√©dio - Melhora UX e estabilidade

---

### 1.3 Processamento Paralelo de M√∫ltiplas NF-es
**Problema**: Se m√∫ltiplas NF-es chegam, s√£o processadas uma por vez

**Solu√ß√£o**: Processar em paralelo com limite de concorr√™ncia

```go
// internal/api/handlers.go
func (h *Handler) BatchUploadHandler(w http.ResponseWriter, r *http.Request) {
    // Receber m√∫ltiplos arquivos
    // Processar em paralelo com sem√°foro
    sem := make(chan struct{}, 5) // M√°ximo 5 simult√¢neas
    var wg sync.WaitGroup
    
    for _, file := range files {
        wg.Add(1)
        go func(f File) {
            defer wg.Done()
            sem <- struct{}{} // Acquire
            defer func() { <-sem }() // Release
            
            // Processar NF-e
        }(file)
    }
    wg.Wait()
}
```

**Impacto**: ‚ö°‚ö°‚ö° Alto - Reduz tempo total de processamento

---

## üìã Fase 2: Cache Avan√ßado e Otimiza√ß√µes de Mem√≥ria (ALTA PRIORIDADE)

### 2.1 Cache com sync.Map para Thread-Safety
**Problema**: Cache atual usa mutex, pode ter conten√ß√£o

**Solu√ß√£o**: Usar sync.Map para leituras concorrentes ou cache mais sofisticado

```go
// internal/api/cache_advanced.go
import (
    "sync"
    "time"
    "github.com/patrickmn/go-cache" // ou implementar pr√≥prio
)

type AdvancedCache struct {
    cache *cache.Cache // go-cache ou implementa√ß√£o pr√≥pria
    mu    sync.RWMutex
}

// Ou usar sync.Map para casos espec√≠ficos
type FastCache struct {
    data sync.Map // map[string]*CacheEntry
}

type CacheEntry struct {
    Value     interface{}
    ExpiresAt time.Time
}
```

**Alternativa**: Usar `github.com/patrickmn/go-cache` que j√° √© thread-safe e tem TTL

**Impacto**: ‚ö°‚ö° M√©dio - Melhora performance de leituras concorrentes

---

### 2.2 Cache de Queries com Invalida√ß√£o Inteligente
**Problema**: Cache atual invalida tudo, mesmo quando n√£o necess√°rio

**Solu√ß√£o**: Cache granular com tags de invalida√ß√£o

```go
type TaggedCache struct {
    entries map[string]*CacheEntry
    tags    map[string][]string // tag -> []keys
    mu      sync.RWMutex
}

func (c *TaggedCache) InvalidateByTag(tag string) {
    // Invalidar apenas entradas com essa tag
    // Ex: tag "product:123" invalida apenas cache relacionado a esse produto
}
```

**Impacto**: ‚ö°‚ö°‚ö° Alto - Reduz invalida√ß√µes desnecess√°rias

---

### 2.3 Object Pooling para Structs Pesadas
**Problema**: Aloca√ß√µes frequentes de structs grandes (ex: relat√≥rios)

**Solu√ß√£o**: Object pooling com sync.Pool

```go
var reportPool = sync.Pool{
    New: func() interface{} {
        return &Report{
            Items: make([]ReportItem, 0, 100), // Pre-alocar slice
        }
    },
}

func getReport() *Report {
    r := reportPool.Get().(*Report)
    r.Reset() // Limpar dados
    return r
}

func putReport(r *Report) {
    reportPool.Put(r)
}
```

**Impacto**: ‚ö°‚ö° M√©dio - Reduz aloca√ß√µes e GC pressure

---

## üìã Fase 3: Graceful Shutdown e Confiabilidade (M√âDIA PRIORIDADE)

### 3.1 Graceful Shutdown Completo
**Problema**: Servidor n√£o fecha conex√µes gracefully

**Solu√ß√£o**: Implementar shutdown com timeout e cleanup

```go
// main.go
func main() {
    // ... setup ...
    
    srv := &http.Server{
        Addr:         ":" + port,
        Handler:      r,
        ReadTimeout:  15 * time.Second,
        WriteTimeout: 15 * time.Second,
        IdleTimeout:  60 * time.Second,
    }
    
    // Canal para sinais do sistema
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)
    
    // Servidor em goroutine
    go func() {
        if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            slog.Error("Server error", "error", err)
        }
    }()
    
    // Aguardar sinal
    <-sigChan
    slog.Info("Shutting down gracefully...")
    
    // Context com timeout para shutdown
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    // Parar worker pools
    nfeConsumer.Stop(ctx)
    exportPool.Stop(ctx)
    
    // Shutdown do servidor HTTP
    if err := srv.Shutdown(ctx); err != nil {
        slog.Error("Server shutdown error", "error", err)
    }
    
    slog.Info("Server stopped")
}
```

**Impacto**: ‚ö°‚ö°‚ö° Alto - Evita perda de dados e conex√µes abertas

---

### 3.2 Retry Logic com Exponential Backoff
**Problema**: Falhas tempor√°rias de DB n√£o s√£o retentadas

**Solu√ß√£o**: Retry com exponential backoff

```go
// internal/utils/retry.go
func RetryWithBackoff(ctx context.Context, maxRetries int, fn func() error) error {
    backoff := time.Second
    
    for i := 0; i < maxRetries; i++ {
        err := fn()
        if err == nil {
            return nil
        }
        
        if i == maxRetries-1 {
            return err
        }
        
        select {
        case <-ctx.Done():
            return ctx.Err()
        case <-time.After(backoff):
            backoff *= 2 // Exponential backoff
            if backoff > 30*time.Second {
                backoff = 30 * time.Second
            }
        }
    }
    return errors.New("max retries exceeded")
}
```

**Impacto**: ‚ö°‚ö° M√©dio - Melhora resili√™ncia

---

### 3.3 Circuit Breaker para Prote√ß√£o
**Problema**: Se DB fica lento, todas requisi√ß√µes ficam lentas

**Solu√ß√£o**: Circuit breaker para isolar falhas

```go
// internal/utils/circuit_breaker.go
type CircuitBreaker struct {
    maxFailures int
    timeout     time.Duration
    failures    int
    lastFailure time.Time
    state       State // Closed, Open, HalfOpen
    mu          sync.RWMutex
}

func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.Lock()
    defer cb.mu.Unlock()
    
    if cb.state == Open {
        if time.Since(cb.lastFailure) > cb.timeout {
            cb.state = HalfOpen // Tentar novamente
        } else {
            return ErrCircuitOpen
        }
    }
    
    err := fn()
    if err != nil {
        cb.failures++
        cb.lastFailure = time.Now()
        if cb.failures >= cb.maxFailures {
            cb.state = Open
        }
        return err
    }
    
    // Sucesso - resetar
    cb.failures = 0
    cb.state = Closed
    return nil
}
```

**Impacto**: ‚ö°‚ö°‚ö° Alto - Protege sistema de sobrecarga

---

## üìã Fase 4: Otimiza√ß√µes de Banco de Dados (M√âDIA PRIORIDADE)

### 4.1 Connection Pooling Otimizado
**Problema**: Pool padr√£o pode n√£o ser otimizado

**Solu√ß√£o**: Configurar pool baseado em carga

```go
// internal/database/db.go
sqlDB, err := db.DB()
if err != nil {
    return err
}

// Configurar pool baseado em carga esperada
sqlDB.SetMaxOpenConns(25)        // M√°ximo de conex√µes abertas
sqlDB.SetMaxIdleConns(10)         // M√°ximo de conex√µes idle
sqlDB.SetConnMaxLifetime(5 * time.Minute) // Tempo m√°ximo de vida
sqlDB.SetConnMaxIdleTime(10 * time.Minute) // Tempo m√°ximo idle
```

**Impacto**: ‚ö°‚ö°‚ö° Alto - Melhora performance e estabilidade

---

### 4.2 Prepared Statements Cached
**Problema**: Queries repetidas n√£o usam prepared statements

**Solu√ß√£o**: Cache de prepared statements

```go
type QueryCache struct {
    stmts map[string]*sql.Stmt
    mu    sync.RWMutex
}

func (qc *QueryCache) GetOrPrepare(db *sql.DB, query string) (*sql.Stmt, error) {
    qc.mu.RLock()
    if stmt, ok := qc.stmts[query]; ok {
        qc.mu.RUnlock()
        return stmt, nil
    }
    qc.mu.RUnlock()
    
    qc.mu.Lock()
    defer qc.mu.Unlock()
    
    // Double-check
    if stmt, ok := qc.stmts[query]; ok {
        return stmt, nil
    }
    
    stmt, err := db.Prepare(query)
    if err != nil {
        return nil, err
    }
    
    qc.stmts[query] = stmt
    return stmt, nil
}
```

**Impacto**: ‚ö°‚ö° M√©dio - Reduz overhead de parsing SQL

---

### 4.3 Batch Operations para Inser√ß√µes
**Problema**: Inser√ß√µes de movimentos s√£o uma por uma

**Solu√ß√£o**: Batch inserts

```go
// internal/services/product_service.go
func (s *ProductService) CreateMovementsBatch(movements []Movement) error {
    if len(movements) == 0 {
        return nil
    }
    
    // Preparar batch insert
    values := make([]string, 0, len(movements))
    args := make([]interface{}, 0, len(movements)*5)
    
    for _, m := range movements {
        values = append(values, "(?, ?, ?, ?, ?)")
        args = append(args, m.ProductCode, m.Type, m.Quantity, m.Origin, m.UserID)
    }
    
    query := fmt.Sprintf(
        "INSERT INTO movements (product_code, type, quantity, origin, user_id) VALUES %s",
        strings.Join(values, ","),
    )
    
    return s.DB.Exec(query, args...).Error
}
```

**Impacto**: ‚ö°‚ö°‚ö° Alto - Reduz tempo de inser√ß√£o de m√∫ltiplos registros

---

## üìã Fase 5: Observabilidade e M√©tricas (BAIXA PRIORIDADE)

### 5.1 M√©tricas com Prometheus
**Solu√ß√£o**: Expor m√©tricas Prometheus

```go
// internal/metrics/metrics.go
import "github.com/prometheus/client_golang/prometheus"

var (
    httpRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )
    
    httpRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request duration",
        },
        []string{"method", "endpoint"},
    )
    
    nfeProcessedTotal = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: "nfe_processed_total",
            Help: "Total NF-e processed",
        },
    )
)

func init() {
    prometheus.MustRegister(httpRequestsTotal)
    prometheus.MustRegister(httpRequestDuration)
    prometheus.MustRegister(nfeProcessedTotal)
}
```

**Impacto**: ‚ö°‚ö° M√©dio - Melhora observabilidade

---

### 5.2 Tracing com OpenTelemetry
**Solu√ß√£o**: Distributed tracing

```go
// internal/tracing/tracing.go
import "go.opentelemetry.io/otel"

func InitTracing(serviceName string) (*trace.TracerProvider, error) {
    // Configurar OpenTelemetry
    // Exportar para Jaeger/Zipkin
}
```

**Impacto**: ‚ö° Baixo - √ötil para debug em produ√ß√£o

---

### 5.3 Profiling Autom√°tico
**Solu√ß√£o**: Endpoint de profiling

```go
// main.go
import _ "net/http/pprof"

go func() {
    log.Println(http.ListenAndServe("localhost:6060", nil))
}()
```

**Impacto**: ‚ö° Baixo - √ötil para otimiza√ß√µes

---

## üìã Fase 6: Otimiza√ß√µes Espec√≠ficas (BAIXA PRIORIDADE)

### 6.1 Rate Limiting por Usu√°rio (n√£o apenas IP)
**Solu√ß√£o**: Rate limiting baseado em user ID

```go
type UserRateLimiter struct {
    limiters map[int32]*rate.Limiter
    mu       sync.RWMutex
}

func (rl *UserRateLimiter) Allow(userID int32) bool {
    rl.mu.RLock()
    limiter, ok := rl.limiters[userID]
    rl.mu.RUnlock()
    
    if !ok {
        rl.mu.Lock()
        limiter = rate.NewLimiter(rate.Every(time.Second), 10) // 10 req/s
        rl.limiters[userID] = limiter
        rl.mu.Unlock()
    }
    
    return limiter.Allow()
}
```

**Impacto**: ‚ö°‚ö° M√©dio - Melhor controle de rate limiting

---

### 6.2 Streaming de Respostas Grandes
**Problema**: Exporta√ß√µes grandes carregam tudo na mem√≥ria

**Solu√ß√£o**: Streaming com http.Flusher

```go
func (h *Handler) StreamExportHandler(w http.ResponseWriter, r *http.Request) {
    flusher, ok := w.(http.Flusher)
    if !ok {
        http.Error(w, "Streaming not supported", http.StatusInternalServerError)
        return
    }
    
    w.Header().Set("Content-Type", "text/csv")
    w.Header().Set("Transfer-Encoding", "chunked")
    
    // Escrever header
    fmt.Fprintf(w, "Code,Name,Quantity\n")
    flusher.Flush()
    
    // Stream dados
    rows, _ := h.DB.Raw("SELECT * FROM stock").Rows()
    defer rows.Close()
    
    for rows.Next() {
        // Processar e escrever linha
        fmt.Fprintf(w, "%s,%s,%d\n", code, name, qty)
        flusher.Flush()
    }
}
```

**Impacto**: ‚ö°‚ö° M√©dio - Reduz uso de mem√≥ria

---

### 6.3 Context Propagation em Toda Aplica√ß√£o
**Solu√ß√£o**: Passar context em todas opera√ß√µes

```go
// Todos handlers devem receber context da request
func (h *Handler) StockHandler(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    
    // Passar context para todas opera√ß√µes
    list, err := h.ProductService.GetStockList(ctx, search, categoryID, page, limit)
    // ...
}
```

**Impacto**: ‚ö°‚ö°‚ö° Alto - Permite cancelamento e timeouts

---

## üéØ Prioriza√ß√£o e Roadmap

### Sprint 1 (2 semanas) - ALTA PRIORIDADE
1. ‚úÖ Worker Pool para NF-e
2. ‚úÖ Graceful Shutdown
3. ‚úÖ Connection Pooling Otimizado
4. ‚úÖ Batch Operations

### Sprint 2 (2 semanas) - ALTA/M√âDIA PRIORIDADE
1. ‚úÖ Worker Pool para Exporta√ß√µes
2. ‚úÖ Cache Avan√ßado (go-cache)
3. ‚úÖ Retry Logic
4. ‚úÖ Context Propagation

### Sprint 3 (2 semanas) - M√âDIA PRIORIDADE
1. ‚úÖ Circuit Breaker
2. ‚úÖ Rate Limiting por Usu√°rio
3. ‚úÖ Streaming de Respostas
4. ‚úÖ M√©tricas B√°sicas

### Sprint 4 (1 semana) - BAIXA PRIORIDADE
1. ‚úÖ Object Pooling
2. ‚úÖ Profiling
3. ‚úÖ Tracing (opcional)

---

## üìä M√©tricas de Sucesso

### Performance
- **Lat√™ncia P95**: Reduzir de ~200ms para ~50ms
- **Throughput**: Aumentar de 100 req/s para 500+ req/s
- **Tempo de processamento NF-e**: Reduzir de 2s para 200ms (com worker pool)

### Confiabilidade
- **Uptime**: 99.9%+
- **Graceful Shutdown**: < 5s
- **Error Rate**: < 0.1%

### Escalabilidade
- **Concorr√™ncia**: Suportar 1000+ usu√°rios simult√¢neos
- **Mem√≥ria**: Reduzir uso em 30% (com object pooling)
- **CPU**: Melhor utiliza√ß√£o de m√∫ltiplos cores

---

## üîß Ferramentas e Bibliotecas Recomendadas

### Concorr√™ncia
- `sync` (stdlib) - WaitGroup, Mutex, RWMutex, Pool, Map
- `golang.org/x/sync` - errgroup, semaphore

### Cache
- `github.com/patrickmn/go-cache` - Cache thread-safe com TTL
- `sync.Map` (stdlib) - Para casos espec√≠ficos

### M√©tricas
- `github.com/prometheus/client_golang` - Prometheus metrics
- `go.opentelemetry.io/otel` - OpenTelemetry tracing

### Rate Limiting
- `golang.org/x/time/rate` - Token bucket rate limiter

### Circuit Breaker
- `github.com/sony/gobreaker` - Circuit breaker pattern

---

## üìù Notas de Implementa√ß√£o

1. **Testes**: Cada feature deve ter testes unit√°rios e de integra√ß√£o
2. **Benchmarks**: Usar `go test -bench` para validar melhorias
3. **Profiling**: Usar `go tool pprof` para identificar bottlenecks
4. **Documenta√ß√£o**: Atualizar documenta√ß√£o t√©cnica com cada mudan√ßa

---

## üöÄ Pr√≥ximos Passos

1. **Revisar plano** com equipe
2. **Priorizar features** baseado em necessidades de neg√≥cio
3. **Criar issues** no GitHub para cada feature
4. **Implementar Sprint 1** (alta prioridade)
5. **Medir resultados** e iterar

---

*√öltima atualiza√ß√£o: 2026-02-10*
*Vers√£o do Plano: 1.0*
